# internlm chat proxy

Proxy for `https://intern-ai.org.cn`.

## Install
```
pnpm install
```

## Usage

1. Create a new `.env` file, and add `INTERNLM_API_KEY`
2. Run `pnpm run dev`
3. Update any openai client and set openai endpoint to `http://127.0.0.1:8653`

And then, chatting will work!

# License

MIT
